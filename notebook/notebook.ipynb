{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import requests as req "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Mangafy "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "\n",
    "### Parse name \n",
    "Parse a string removing and replacing unwanted characters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_name(name):\n",
    "\tprint(\"Parsing {}\".format(name))\n",
    "\tname_to_return = name\n",
    "\tallowed_characters = \"QWERTYUIOPLKJHGFDSAZXCVBNMqwertyuioplkjhgfdsazxcvbnm-_\"\n",
    "\tfor x in name_to_return:\n",
    "\t\tif x in allowed_characters:\n",
    "\t\t\tcontinue\n",
    "\t\tif x == '&':\n",
    "\t\t\tname_to_return = name_to_return.replace(x, 'and')\n",
    "\t\tname_to_return = name_to_return.replace(x, ' ')\n",
    "\tprint(\"Result: {}\".format(name_to_return))\n",
    "\treturn name_to_return\n",
    "\n",
    "#test\n",
    "tesr_string = 'jwefnw44ouh034jtrh380th3obg0934tp24[pri0394utop3mtoih3490tj23rnpi2h3r[j23pitgp2o34jtoi34ht[pk'\n",
    "print(parse_name(tesr_string))"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "### Manga Genre Scrapper \n",
    "Scrape the first ten manga from the specified url (must be a valid genres page on manganelo.com)\n",
    "> Example **https://manganelo.com/genre-all?type=newest**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "manga_list = []\n",
    "\n",
    "def genre_scrape(url):\n",
    "    manga_list.clear()\n",
    "    \"\"\"WARNING: url must be a valid url to one of the genres page on manganelo.com\"\"\"    \n",
    "    uClient = req.get(url)\n",
    "    client_html = uClient.text\n",
    "    client_soup = soup(client_html, 'lxml')\n",
    "    homepage_items = client_soup.findAll(\"div\",{\"class\":\"content-genres-item\"})\n",
    "    print('Found {} manga'.format(len(homepage_items)))\n",
    "    index = 0\n",
    "\n",
    "    for homepage_item in homepage_items:\n",
    "        try:\n",
    "            manga_name = parse_name(homepage_item.div.h3.a.text)\n",
    "            latest_chapter_box = homepage_item.find(\"a\",{\"class\":\"genres-item-chap text-nowrap a-h\"})\n",
    "            if latest_chapter_box == None:\n",
    "                latest_chapter = \"Unable to fetch latest chapter\"\n",
    "            else:\n",
    "                latest_chapter = latest_chapter_box.text\n",
    "            manga_link = homepage_item.div.h3.a[\"href\"]\n",
    "\n",
    "            manga_list.append({\"Name\":manga_name, \"Link\":manga_link, \"Latest_chapter\":latest_chapter})\n",
    "\n",
    "            index = index + 1\n",
    "            if index == 10:\n",
    "                break\n",
    "        except UnboundLocalError:\n",
    "            print(\"local variable 'index' referenced before assignment\")\n",
    "        except:\n",
    "            print('An error occoured')\n",
    "\n",
    "    return manga_list\n",
    "\n",
    "#test\n",
    "test_url = 'https://manganelo.com/genre-all?type=newest'\n",
    "print(genre_scrape(test_url))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "---\n",
    "\n",
    "### Get Manga Data \n",
    "Get the manga data from a list of alerts\n",
    ">```\n",
    ">#alert list sample\n",
    ">{\n",
    ">    'manga1': 'manga1_link',\n",
    ">    'manga2': 'manga2_link',\n",
    ">    'manga3': 'manga3_link'\n",
    ">} \n",
    ">```\n",
    "\n",
    "And returns it in the following format\n",
    ">```\n",
    ">[\n",
    ">    {'name': 'manga1', 'link': 'manga1_link', 'latest_chapter': 'latest_chapter'},\n",
    ">    {'name': 'manga2', 'link': 'manga2_link', 'latest_chapter': 'latest_chapter'},\n",
    ">    {'name': 'manga3', 'link': 'manga3_link', 'latest_chapter': 'latest_chapter'}\n",
    ">] \n",
    ">```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_updates(alert_list):\n",
    "\n",
    "    manga_list = []\n",
    "\n",
    "    for x in alert_list:\n",
    "\n",
    "        uClient = req.get(alert_list[x])\n",
    "        client_html = uClient.text\n",
    "        client_soup = soup(client_html, 'lxml')\n",
    "\n",
    "        homepage_item = client_soup.find(\"li\", {\"class\": \"a-h\"})\n",
    "\n",
    "        latest_chapter = homepage_item.a.text\n",
    "        latest_chapter_link = homepage_item.a['href']\n",
    "\n",
    "        manga_list.append(\n",
    "            {\"name\": x, \"link\": alert_list[x], \"latest_chapter\": latest_chapter, \"latest_chapter_link\": latest_chapter_link})\n",
    "\n",
    "    return manga_list"
   ]
  }
 ]
}